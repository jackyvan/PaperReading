### Graph Convolutional Network

2.《semi-supervised classification with graph convolutional network》,iclr2017

应该是最早提出gcn的文章，文章给出了tf的代码，后来作者又给出了pt，keras等各个版本下的代码。rgb以写faster-rcnn来打发无聊的时候，不知道kipf是不是靠写gcn来排遣空闲。这里的应用场景是半监督分类。典型的一个例子是论文分类+论文引用信息。论文引用构成了一个graph，graph包含的丰富的信息。比如，相关类别的论文有更大的可能应用同类别的论文。因此如何将graph的信息融合进分类任务从而帮助分类效果的提升就是一个关键了。因为需要处理的数据是graph形式的，因此就多了一些特色。类似的处理场景在nlp下有kg知识的融合，之前做的一个事情是简单的将kg中的三元组concat后embedding到网络中，从而确实提升了对话效果，能否将gcn用于kg是一个值得思考的问题。由于是最早的工作，作者做了两层的gcn，从结构上的设计来看，更像是一个前馈网络的形式。这篇文章提供了应用gcn的原始建模思路，值得借鉴。这里给出[pygcn的代码地址](https://github.com/tkipf/pygcn)，代码基于一个论文引用网络做文本分类，结构非常清晰易懂。

1.《Multi-Label Image Recognition with Graph Convolutional Networks》

0.《Graph Convolutional Networks for Text Classification
》

想法：0和1是两篇关于gcn的文章。印象中18年年底和19年年初，gcn的综述文章出了至少有三篇。0的思路是这样的，将文本分类转化为一个graph上的node分类问题。很显然，这里的node要满足\#node>=c，其中c是类别总数。既然是graph，不仅需要node，还需要edge。在文章中，node有两类组成，分别是document和word，那么edge的信息就是document和word的关联关系的表示了。比较容易想到的有经典的tf-idf，co-currence等，在论文中词与词之间的关联关系表示用了pmi，也是一个统计量。这样的话，图就构造结束了。对文档分类，损失函数只考虑node类型为document的就可以了。

1是cvpr2019的文章。multi-label问题的关键之一是要考虑：**标签依赖**。那么用graph来建模这种依赖关系好了，这样还是node分类问题，edge表示的关联信息来自对数据集中标签的统计量，典型的co-currence。不过仅仅通过co-currence得到的edge关系在数值上是不完美的，文章对edge关系进行了基于weight的修正。文章堆叠了gcn，最后输出的矩阵维度为\#node\*#d。对图片的特征提取就是一个普通的cnn网络，最后输出的矩阵维度为\#d，两类输出做点积就是类别预测向量了(
\#node=\#c)。

扩展：针对细粒度情感分类问题（如ai challenger2018赛道），或许也可以用gcn来做。对评论文本的特征提取用任意一个好的结构来做。将标签展开成20个label，显然label之间是有着依赖关系的，比如性价比和折扣力度是正相关的。对label本身embedding做为node feature，edge信息如何算？一种思路是计算情感值的差，这样的话，edge的信息就是一个多维向量了。剩下的事情和1差不多。不过，由于标签存在层次结构，因此或许可以利用一下。此外，attention能否在这种场景下得到应用也值得思考。


